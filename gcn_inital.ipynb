{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from dgl import DGLGraph\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('soil_moisture.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('soil_moisture.csv')\n",
    "\n",
    "sampled_df = df.sample(frac=0.10, random_state=42)\n",
    "\n",
    "features = sampled_df[['Clay_0cm', 'Elevation', 'LST_Day_1km', 'LST_Night_1km', 'Precipitation', 'Sand_0cm',\n",
    "                       'Soil_Moisture', 'SolarZenith', 'latitude', 'longitude', 'sur_refl_b01', 'sur_refl_b02',\n",
    "                       'sur_refl_b03', 'sur_refl_b04', 'sur_refl_b05', 'sur_refl_b06', 'sur_refl_b07']].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "n_nodes = 150\n",
    "nodes = np.column_stack((np.random.uniform(sampled_df['latitude'].min(), sampled_df['latitude'].max(), n_nodes),\n",
    "                         np.random.uniform(sampled_df['longitude'].min(), sampled_df['longitude'].max(), n_nodes)))\n",
    "\n",
    "node_assignments = np.argmin(np.linalg.norm(nodes[:, None] - sampled_df[['latitude', 'longitude']].values, axis=2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saagar/Coding/major_project/venv/lib/python3.10/site-packages/dgl/heterograph.py:92: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning(\n"
     ]
    }
   ],
   "source": [
    "g = DGLGraph()\n",
    "g.add_nodes(n_nodes)\n",
    "edges = []\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    for j in range(i+1, n_nodes):\n",
    "        dist = np.linalg.norm(nodes[i] - nodes[j])\n",
    "        if dist < 500:\n",
    "            edges.append((i, j))\n",
    "\n",
    "src, dst = zip(*edges)\n",
    "g.add_edges(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(np.arange(n_nodes), test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = sampled_df['Soil_Moisture'].values\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_target = MinMaxScaler()\n",
    "targets = scaler_target.fit_transform(targets.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, out_feats):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            dgl.nn.GraphConv(in_feats, hidden_size),\n",
    "            dgl.nn.GraphConv(hidden_size, out_feats)\n",
    "        ])\n",
    "\n",
    "    def forward(self, g, inputs):\n",
    "        h = inputs\n",
    "        for layer in self.layers:\n",
    "            h = layer(g, h)\n",
    "        return h\n",
    "\n",
    "model = GNNModel(in_feats=features.shape[1], hidden_size=64, out_feats=1)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to() received an invalid combination of arguments - got (numpy.ndarray), but expected one of:\n * (torch.device device, torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (Tensor tensor, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/saagar/Coding/major_project/gcn_inital.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         \u001b[39mif\u001b[39;00m (epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch [\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m] Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m train(model, g, features, targets, train_idx, optimizer, criterion, \u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/home/saagar/Coding/major_project/gcn_inital.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(model, g, inputs, targets, train_idx, optimizer, criterion, epochs\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         outputs \u001b[39m=\u001b[39m model(g, inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         loss \u001b[39m=\u001b[39m criterion(outputs[train_idx], targets[train_idx])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Coding/major_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Coding/major_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/saagar/Coding/major_project/gcn_inital.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m h \u001b[39m=\u001b[39m inputs\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     h \u001b[39m=\u001b[39m layer(g, h)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/saagar/Coding/major_project/gcn_inital.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m h\n",
      "File \u001b[0;32m~/Coding/major_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Coding/major_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Coding/major_project/venv/lib/python3.10/site-packages/dgl/nn/pytorch/conv/graphconv.py:428\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    426\u001b[0m feat_src, feat_dst \u001b[39m=\u001b[39m expand_as_pair(feat, graph)\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_norm \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 428\u001b[0m     degs \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39;49mout_degrees()\u001b[39m.\u001b[39;49mto(feat_src)\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    429\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_norm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    430\u001b[0m         norm \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mpow(degs, \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: to() received an invalid combination of arguments - got (numpy.ndarray), but expected one of:\n * (torch.device device, torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (torch.dtype dtype, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n * (Tensor tensor, bool non_blocking, bool copy, *, torch.memory_format memory_format)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "lr = 0.001  # Learning rate\n",
    "\n",
    "g = dgl.add_self_loop(g)\n",
    "\n",
    "dgl.nn.GraphConv(features.shape[1], 1, allow_zero_in_degree=True)\n",
    "\n",
    "def train(model, g, inputs, targets, train_idx, optimizer, criterion, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        outputs = model(g, inputs)\n",
    "        loss = criterion(outputs[train_idx], targets[train_idx])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}] Loss: {loss.item()}')\n",
    "\n",
    "train(model, g, features, targets, train_idx, optimizer, criterion, 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
